<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://dandelionym.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dandelionym.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-02T06:45:50+00:00</updated><id>https://dandelionym.github.io/feed.xml</id><title type="html">Mellen Y. Pu</title><subtitle>Mellen&apos;s personal website. </subtitle><entry><title type="html">Materials Science: The Inspiring Intersection with Generative AI</title><link href="https://dandelionym.github.io/blog/2025/materials-science-the-inspiring-intersection-with-generative-ai/" rel="alternate" type="text/html" title="Materials Science: The Inspiring Intersection with Generative AI"/><published>2025-03-17T18:22:53+00:00</published><updated>2025-03-17T18:22:53+00:00</updated><id>https://dandelionym.github.io/blog/2025/materials-science-the-inspiring-intersection-with-generative-ai</id><content type="html" xml:base="https://dandelionym.github.io/blog/2025/materials-science-the-inspiring-intersection-with-generative-ai/"><![CDATA[<blockquote>I always ask myself, what is the next milestone of AI+Material Science? Problems with diverse views may lead to unexplored areas that hidden in our cognition, they should be noticed and well formulated now, but, well, we are not alone, some thoughts might be pretty clear here… ☕️</blockquote> <h3>Introduction</h3> <p>Materials science is a fascinating field that sits at the intersection of physics, chemistry, and engineering. From the silicon that powers our computers to the polymers in our everyday products, materials science touches nearly every aspect of our lives. Its interdisciplinary nature bridges the gap between pure scientific inquiry and practical, real-world innovation, making it a critical driver of technological progress.</p> <p>In recent years, the rise of artificial intelligence (AI) — particularly large language models (LLMs) and generative AI — has opened up exciting new possibilities for materials science. These cutting-edge technologies are poised to revolutionize <strong>how we discover, design, and optimize materials</strong>. However, with these opportunities come unique challenges that must be addressed to fully unlock the potential of AI in this field. In this post, we’ll explore the distinctive role of materials science in the natural sciences, delve into how AI is transforming the field, and discuss the hurdles and future prospects of this inspiring intersection.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/700/0*z8DVXIOxGQz1DxpY"/><figcaption>AI Supervisor for Materials Science Experiments and Research, generated by Midjourney.</figcaption></figure> <p><strong>The Uniqueness of Materials Science. </strong>What sets materials science apart from other natural sciences is its dual focus on <strong>understanding</strong> and <strong>creating</strong>. While physics might explore the fundamental particles that make up matter and chemistry might investigate how atoms bond to form molecules, materials science takes these insights and asks, “<strong><em>How can we use this knowledge to build something useful?</em></strong>” It’s a field driven by both curiosity and application, where researchers study everything from the <strong>atomic structure</strong> of a crystal to the <strong>macroscopic behavior</strong> of a composite material, all with the goal of solving real-world problems.</p> <p>Materials scientists work across <strong>scales</strong> — ranging from the nanoscale to the macroscale — and <strong><em>draw on principles from multiple disciplines to manipulate materials in ways that enhance their performance</em></strong>. This could mean developing lighter and stronger alloys for aerospace, creating more efficient solar cells to combat climate change, or designing biocompatible materials for medical implants. The field’s inherent interdisciplinarity and its direct link to technological innovation make it uniquely positioned to address some of the world’s most pressing challenges.</p> <h3>Techniqes &amp; Challenges</h3> <p><strong>AI’s Transformative Potential in Materials Science</strong></p> <p>The advent of AI, particularly large language models and generative AI, has introduced powerful new tools that are reshaping the landscape of materials science. These technologies offer unprecedented capabilities for <strong>processing vast amounts of data, generating novel ideas, and accelerating the discovery process</strong>. Let’s take a closer look at how they are making an impact.</p> <p><strong>Large Language Models: Unlocking Insights from Data</strong></p> <p>Large language models, such as GPT-4, have demonstrated remarkable abilities to understand and generate human-like text. In materials science, these models can be harnessed to analyze enormous volumes of scientific literature, extracting key findings, identifying trends, and even predicting material properties. For example, <strong>an LLM could be tasked with sifting through thousands of research papers on battery materials to identify common characteristics of high-performance designs</strong>. This would save researchers countless hours and provide insights that might otherwise be missed.</p> <p>Moreover, LLMs can assist in hypothesis generation. By analyzing existing data and identifying patterns, these models can suggest new avenues for exploration, such as predicting how a novel combination of elements might yield a material with superior strength or conductivity. While LLMs are not a replacement for experimental validation, they can significantly narrow the search space, making the discovery process more efficient.</p> <p><strong>Challenges at the Intersection of AI and Materials Science</strong></p> <p>While the promise of AI in materials science is immense, several challenges must be overcome to fully realize its potential. These challenges stem from the unique nature of materials data and the need for models that are both accurate and interpretable.</p> <ol><li><strong>Data Quality and Availability</strong></li></ol> <p>Materials science data is notoriously complex and heterogeneous. It comes from a <strong>variety of sources, including experiments, simulations, and literature, and often lacks standardization</strong>. For example, different research groups might use varying methods to measure the same property, leading to inconsistencies in the data. Additionally, materials data can be sparse, especially for newly discovered or highly specialized materials. This makes it difficult to train robust AI models, which typically require large, high-quality datasets.</p> <p>To address this, efforts are underway to create standardized, open-access databases of materials properties, such as the <strong>Materials Project</strong> or the Novel Materials Discovery (NOMAD) repository. These initiatives aim to aggregate and curate data from diverse sources, providing a foundation for AI-driven research. However, significant work remains to ensure that these datasets are comprehensive and reliable.</p> <p><strong>2. Interpretability: Understanding the “Why”</strong></p> <p>In materials science, it’s not enough for an AI model to make accurate predictions; researchers need to understand <strong>why</strong> a model makes a particular prediction. This is crucial for gaining new scientific insights and building trust in AI-driven discoveries. Unfortunately, many advanced AI models, particularly deep learning models, are often seen as “black boxes” due to their complexity.</p> <p>To tackle this issue, the field of explainable AI (XAI) is gaining traction. XAI techniques aim to make AI models more transparent by providing explanations for their predictions. For example, in a model predicting the strength of a material, XAI methods could highlight which features — such as atomic bonding or grain structure — were most influential in the prediction. By integrating XAI into materials science, researchers can ensure that AI is not just a tool for prediction but also a source of deeper understanding.</p> <p><strong>3. Integrating AI with Traditional Methods</strong></p> <p>Another challenge lies in integrating AI with traditional materials science workflows. Many materials scientists are accustomed to experimental or computational approaches and may be hesitant to adopt AI-driven methods. Bridging this gap requires not only developing user-friendly AI tools but also fostering interdisciplinary collaboration between AI experts and materials scientists.</p> <p>Educational initiatives and cross-disciplinary research projects are essential for building this bridge. By training the next generation of materials scientists to be fluent in both traditional methods and AI techniques, the field can fully embrace the potential of this intersection.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*q-48hQKi2Ra3W3lq"/><figcaption>AI Center for creating materials, generated by Midgourney.</figcaption></figure> <p><strong>Overcoming Challenges and Looking Ahead</strong></p> <p>Despite these challenges, the future of AI in materials science is bright. Researchers are actively developing new strategies to address data issues, improve model interpretability, and integrate AI with traditional approaches. For instance, the Materials Genome Initiative, launched in 2011, aims to accelerate materials discovery by combining high-throughput computing, data sharing, and machine learning. Similarly, advances in transfer learning and few-shot learning are enabling AI models to make accurate predictions even with limited data, which is particularly valuable in materials science.</p> <p>As these efforts bear fruit, we can expect to see AI playing an increasingly central role in materials discovery and design. In the coming years, AI-driven innovations could lead to breakthroughs in areas such as:</p> <ul><li><strong>Energy storage</strong>: Designing next-generation batteries with higher capacity and faster charging times.</li><li><strong>Healthcare</strong>: Creating biocompatible materials for implants or drug delivery systems.</li><li><strong>Sustainability</strong>: Developing materials for efficient solar cells, carbon capture, or lightweight, fuel-efficient vehicles.</li></ul> <p>Moreover, as AI technologies continue to evolve, we may see the emergence of autonomous laboratories where AI not only designs new materials but also directs robotic systems to synthesize and test them. This “closed-loop” approach could dramatically speed up the materials development cycle, bringing new technologies to market faster than ever before.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*B2iyIZeVpcdXf2GP"/><figcaption>Generated by Midjourney.</figcaption></figure> <h3><strong>Conclusion</strong></h3> <p>Materials science has always been a field defined by its ability to turn scientific understanding into tangible innovations. The integration of AI, particularly large language models and generative AI, represents a new chapter in this story — one where the pace of discovery is accelerated, and the boundaries of what’s possible are expanded. While challenges remain, the ongoing efforts to address them are paving the way for a future where AI and materials science work hand in hand to solve some of the world’s most pressing problems.</p> <p>As we stand on the brink of this exciting frontier, it’s clear that the synergy between materials science and AI will not only drive technological progress but also deepen our understanding of the natural world. The journey ahead is full of promise, and the discoveries we make along the way will shape the future in ways we can only begin to imagine.</p> <h4>A Message from AI Mind</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/250/0*5Wm7sOfTpe5DEbhg.gif"/></figure> <p>Thanks for being a part of our community! Before you go:</p> <ul><li>👏 Clap for the story and follow the author 👉</li><li>📰 View more content in the <a href="https://pub.aimind.so/">AI Mind Publication</a></li><li>🧠 Improve your <a href="https://www.aimind.so/prompt-generator?utm_source=pub&amp;utm_medium=message">AI prompts effortlessly and FREE</a></li><li><strong>🧰 Discover </strong><a href="https://www.aimind.so/?utm_source=pub&amp;utm_medium=message"><strong>Intuitive AI Tools</strong></a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8bd40a1c5b03" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://pub.aimind.so/materials-science-the-inspiring-intersection-with-generative-ai-8bd40a1c5b03">Materials Science: The Inspiring Intersection with Generative AI</a> was originally published in <a href="https://pub.aimind.so">AI Mind</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Physicochemical Principles in Material Synthesis: From Language Modeling Perspective</title><link href="https://dandelionym.github.io/blog/2025/physicochemical-principles-in-material-synthesis-from-language-modeling-perspective/" rel="alternate" type="text/html" title="Physicochemical Principles in Material Synthesis: From Language Modeling Perspective"/><published>2025-03-17T18:22:47+00:00</published><updated>2025-03-17T18:22:47+00:00</updated><id>https://dandelionym.github.io/blog/2025/physicochemical-principles-in-material-synthesis-from-language-modeling-perspective</id><content type="html" xml:base="https://dandelionym.github.io/blog/2025/physicochemical-principles-in-material-synthesis-from-language-modeling-perspective/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pfgI7hYBK5Am468_uVxHKg.png"/><figcaption>Generated by Midjourney.</figcaption></figure> <blockquote>In recent years, large language models (LLMs) have demonstrated remarkable potential in scientific discovery through automated experimentation and planning.</blockquote> <blockquote>While research has concentrated on computational design of molecular materials and crystal structures — domains rich in digital datasets —<strong> the more complex field of materials synthesis science remains underexplored.</strong> I contend that AI+Materials Synthesis represents a critical new frontier. Material synthesis presents unique challenges through its multiscale physicochemical complexity and experimental nature.</blockquote> <blockquote>The following discussion examines <strong>why this integration is necessary </strong>and <strong>how it might bridge the gap</strong> between correlative patterns and causal understanding of synthesis mechanisms.</blockquote> <h4>Materials Synthesis as Frontiers</h4> <p>In short, create materials and control their creation.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*thQWvc1EnE0L5LZhf0Dh7g.png"/><figcaption><strong>Figure 1</strong>. Material synthesis loop and synthesis mechanisms.</figcaption></figure> <p>Material synthesis is fundamentally a <strong>cyclical process</strong> of <strong>refinement</strong>. As depicted in the <strong>Figure</strong> <strong>1</strong>, synthesis follows a continuous loop of experiment conditions, variable adjustment, and diverse observations. This iterative cycle drives our understanding forward, with each revolution potentially bringing us closer to materials with desired properties.</p> <p>The synthesis mechanisms can be divided into the combination of <strong>correlation</strong> and <strong>causality</strong>. While correlations are abundant in scientific literature — like the observation that <em>ligands bind predominantly to sharp tips of gold nano-bipyramids with high surface energy </em>— true causal understanding remains elusive. Another tips might be, sometimes we even mistakenly treat the correlations into causality. That is the <strong>knowledge</strong> <strong>scope issue</strong>.</p> <h4>An Example of the Causality:</h4> <p>Consider how temperature affects a material’s formation, as an example of nanoparticles: we observe smaller silver nanoparticles (15–25nm) at lower temperatures (20–25°C), but the causal mechanism involves nucleation kinetics following the relationship: <em>Nucleation rate ∝ exp(-Ea/kT)</em></p> <p><strong>Synthesize materials with expected property involves the understanding of underlying causality — based on physicochemical principles or laws.</strong></p> <h4>Why Traditional Deep Learning Falls Short?</h4> <p>Deep learning approaches, particularly graph neural networks (GNN, refer to <a href="https://en.wikipedia.org/wiki/Graph_neural_network">https://en.wikipedia.org/wiki/Graph_neural_network</a>), offer promising pathways to bridge this gap by modeling complex synthesis pathways and extracting causal relationships from learned representations, potentially transforming materials discovery from correlation-driven to causality-informed science.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Zr10gNXDsMp9bLOASTUNZw.png"/><figcaption>Graph representation of a molecule.</figcaption></figure> <p>Graph neural networks excel at <strong>capturing complex relationships in high-dimensional space</strong>. They transform materials discovery from correlation-driven observations to causality-informed science by learning from extensive training data. However, they struggle with hierarchical structure and multi-scale interactions critical in material synthesis. We actually need this in semantic level — that’s why the scientists work with strict logics.</p> <h4>Today’s Paradigm: Language Models for Knowledge Representation</h4> <p>Yes, it just like a robot saying a lot of words through human languages, but with less logics.</p> <p>Current large language models with the ability of super intelligence operate primarily in the realm of correlation, yet their potential extends toward capturing elements of causality. Their responses are fundamentally based on the <strong>grasping of physicochemical mechanisms extracted from scientific literature</strong>. This represents both their greatest strength and their most significant limitation.</p> <h4>At 80% of Physiochemical Principles Grasping</h4> <p>We utilized LLMs such as Vicuna, Qwen and ChatGPT etc, to test their ability in grasping underlying physicochemical principles. Unlike purely statistical approaches, LLMs can integrate knowledge across disparate studies, potentially identifying patterns invisible to human researchers working within specialized subfields. In short, <strong>they excel at recognizing scientific mechanisms described in literature and can rapidly synthesize information across thousands of papers.</strong></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WEusGpVBjTyiflU5jIKMPA.png"/><figcaption><strong>Experiment Results. </strong>LLM’s benchmark on Physicochemical Principles’s understanding. (<a href="https://openreview.net/pdf?id=I6jYRbaai8">https://openreview.net/pdf?id=I6jYRbaai8</a>)</figcaption></figure> <p>In the rapidly evolving landscape of LLMs, performance metrics remain a critical benchmark for assessing progress. As illustrated in the figure of <strong>Experiment Results,</strong> model size demonstrates a clear correlation with accuracy, with larger architectures consistently outperforming their smaller counterparts. The x-axis represents different models categorized by parameter count (from 7B to Large size), while y-axis displays the accuracy scores ranging from 0.45 to 0.85. Notably, the largest models (represented by the Anthropic “A” logo) achieve remarkable accuracy of 0.85, substantially outperforming smaller variants. <strong>This performance gap underscores the continuing importance of scale in advancing model capabilities</strong>, though the precise architectural differences between models likely play a significant role in the variations observed within similar size categories. Well, the scale is just one method to improve further.</p> <h4>Limitations of LLMs for <em>Understanding</em> Physicochemical Principles</h4> <p>The word <em>Understanding </em>may better be the <em>Grasping. Though LLMs behave like humans, they </em>still fail is in questions <strong>requiring novel mechanistic reasoning</strong>. They cannot simulate the physical world from first principles. <strong>When asked to explain the complex physicochemical processes of material formation, they struggle to bridge the gap between known correlative patterns and true causal understanding.</strong></p> <p>This <strong>limitation</strong> stems from their fundamental architecture:</p> <ol><li>They process text rather than matter</li><li>They lack the ability to perform computational simulations internally</li><li>They cannot test hypotheses experimentally</li><li>They struggle with multi-scale phenomena spanning quantum to macroscopic levels</li></ol> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6dkxF4bzCoRrpXb-oNVPkQ.png"/><figcaption>RAG-based LLM assistant (the bottom one) for gold nanoparticle synthesis mechanism explanation, compared to GPT-4 model (top).</figcaption></figure> <h4>Future direction: a perspective</h4> <p><strong>Literature mining through LLMs presents a powerful approach to accelerate materials science research.</strong> By extracting patterns from thousands of papers, these models can identify correlations that might suggest causal mechanisms.</p> <p>Yes, the key advantage of such systems is still <strong>the</strong> <strong>speed and the breadth</strong>. While human researchers might spend months reviewing literature in a narrow domain, LLMs can process the entire corpus of materials science in seconds, identifying patterns across subdisciplines.</p> <h4>Reference</h4> <p>Pu, Yingming, et al. “Leveraging Large Language Models for Explaining Material Synthesis Mechanisms: The Foundation of Materials Discovery.” <em>AI for Accelerated Materials Design-NeurIPS 2024</em>.</p> <h4>A Message from AI Mind</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/250/0*5Wm7sOfTpe5DEbhg.gif"/></figure> <p>Thanks for being a part of our community! Before you go:</p> <ul><li>👏 Clap for the story and follow the author 👉</li><li>📰 View more content in the <a href="https://pub.aimind.so/">AI Mind Publication</a></li><li>🧠 Improve your <a href="https://www.aimind.so/prompt-generator?utm_source=pub&amp;utm_medium=message">AI prompts effortlessly and FREE</a></li><li><strong>🧰 Discover </strong><a href="https://www.aimind.so/?utm_source=pub&amp;utm_medium=message"><strong>Intuitive AI Tools</strong></a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ff12c28ac1fc" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://pub.aimind.so/physicochemical-principles-in-material-synthesis-from-language-modeling-perspective-ff12c28ac1fc">Physicochemical Principles in Material Synthesis: From Language Modeling Perspective</a> was originally published in <a href="https://pub.aimind.so">AI Mind</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Person and Mural</title><link href="https://dandelionym.github.io/blog/2025/person-and-mural/" rel="alternate" type="text/html" title="Person and Mural"/><published>2025-03-16T07:38:02+00:00</published><updated>2025-03-16T07:38:02+00:00</updated><id>https://dandelionym.github.io/blog/2025/person-and-mural</id><content type="html" xml:base="https://dandelionym.github.io/blog/2025/person-and-mural/"><![CDATA[<p><em>A poem, for the past years, rain, snow and wind &amp; all thoughts.</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uaXpxVpv-5iWEFlB6NqNeQ.jpeg"/></figure> <p><em>The sunset is time’s Adam’s apple — <br/>Each day I watch it lodge at the golden summit of western hills<br/>My shadow and I<br/>Remain silent for ages<br/>The motorway by the building, like an artery,<br/>Frantically ferries the twilight<br/>Mist escapes the mountains’ encirclement, smokestacks in the distant expanse<br/>Suddenly seem incongruous<br/>Everything shall come to pass. My shadow and I<br/>Steel ourselves against one another<br/>Like sunset-stained vine veins sprouting thorns<br/>Nearby, mallards call from the river<br/>The abbey begins its vespers<br/>Let us not lose heart, feigning life<br/>In this purely human realm</em></p> <h4>Author Note:</h4> <p>This is a Chinese poem written by the author, at 2019.</p> <blockquote>© 人与壁画</blockquote> <blockquote>落日是岁月的喉结<br/>每一天我看着它噎在金黄色的西山顶<br/>我与我的影子，都会<br/>沉默很久<br/>楼旁的高速公路像支血管<br/>争分夺秒地搬运着暮色<br/>薄雾脱离了群山的围剿，远处广垣的烟囱<br/>恍然有些突兀<br/>总会了结的。我与影子彼此<br/>相互鼓足了劲<br/>像夕阳晕染过的藤脉长出了刺<br/>不远处，河水里传出水鸭的响声<br/>教堂里开始诵经了<br/>让我们不要失去信心，自己仿佛活着<br/>在这纯粹的人间</blockquote> <p>Yes... Time passes in a blur, days moving faster and faster.</p> <p>Life’s comings and goings always illustrate intersections and parallel lines. Conversing with your own shadow is, without doubt, searching for some inner source or origin.</p> <p>The world created by thought often flows like a babbling river; passing vehicles kick up the dust of four seasons, and along with flower petals and the setting sun, gradually learn to become intoxicated.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9e00839adf71" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">AI for Material Synthesis Science: A Brief Introduction</title><link href="https://dandelionym.github.io/blog/2025/ai-for-material-synthesis-science-a-brief-introduction/" rel="alternate" type="text/html" title="AI for Material Synthesis Science: A Brief Introduction"/><published>2025-02-21T18:31:01+00:00</published><updated>2025-02-21T18:31:01+00:00</updated><id>https://dandelionym.github.io/blog/2025/ai-for-material-synthesis-science-a-brief-introduction</id><content type="html" xml:base="https://dandelionym.github.io/blog/2025/ai-for-material-synthesis-science-a-brief-introduction/"><![CDATA[<p><strong>Q: What can today’s AI do for Science?</strong></p> <p><strong>A: Simply, I say, <em>reading</em>, <em>writting</em>, <em>hypothesizing</em>, and <em>solving</em>.</strong></p> <h3>Introduction</h3> <p>The integration of artificial intelligence, particularly deep learning and language models, has revolutionized the approach to materials synthesis. Deep learning architectures, including convolutional neural networks (CNNs) and graph neural networks (GNNs), have demonstrated remarkable capabilities in <strong>predicting material properties and optimizing synthesis conditions</strong>. These models can process complex structural data and composition-property relationships that were previously challenging to analyze through traditional computational methods.</p> <p>Large language models have emerged as powerful tools for scientific knowledge extraction and synthesis planning. By training on vast corpora of materials science literature, these models can extract synthesis protocols from scientific papers, generate hypotheses about novel material combinations, predict reaction conditions based on precursor materials, and identify patterns in successful synthesis strategies across different material classes.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*_i_8EPHId9Ovy-0zKB7Qxg.png"/><figcaption>Particles in material synthesis, generated by Grok from X.</figcaption></figure> <h3>Materials Synthesis: Optimization and Constraints</h3> <p>Materials synthesis represents a multifaceted optimization challenge where scientists must navigate complex property spaces while considering practical constraints. The optimization of material properties encompasses mechanical attributes such as strength and elasticity, electronic characteristics including conductivity and band gap, thermal properties like heat capacity and conductivity, and chemical aspects such as reactivity and stability. These properties often exhibit intricate interdependencies, requiring careful balance during synthesis.</p> <p>The practical aspects of materials synthesis extend beyond theoretical optimization. Scientists must consider the economic viability of their synthesis routes, including raw material costs, energy requirements, and necessary infrastructure investments. Environmental sustainability has become increasingly crucial, driving the development of greener synthesis methods and more efficient resource utilization. The scalability of laboratory procedures to industrial production presents additional challenges, as processes that work well at small scales may encounter unexpected complications during scale-up.</p> <p>Process control represents another critical dimension of materials synthesis. Success often depends on precise manipulation of temperature profiles, pressure conditions, and atmospheric composition. The relationship between precursor ratios, concentrations, and final product properties requires careful understanding and control of reaction kinetics. These parameters must be optimized while maintaining reproducibility and reliability across different synthesis batches.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Nr6lVhirx_xcc-fBWuJFVg.png"/><figcaption>AI Robot, generated by Grok 3 from X.</figcaption></figure> <h3>Integration of AI with Experimental Workflows</h3> <p>Modern materials synthesis has evolved into a sophisticated interplay between artificial intelligence and automated experimental platforms. Predictive modeling serves as the cornerstone of this integration, with machine learning models generating insights about optimal synthesis conditions. Bayesian optimization frameworks guide experimental design by suggesting the most informative experiments to perform, while uncertainty quantification helps researchers understand the reliability of model predictions.</p> <p>High-throughput experimentation has become increasingly sophisticated through automation and real-time analysis capabilities. Advanced characterization techniques provide rapid feedback about material properties and structure, enabling dynamic adjustment of synthesis parameters. This creates a powerful feedback loop where experimental results continuously inform and improve predictive models.</p> <p>The integration of theoretical calculations, including density functional theory and molecular dynamics simulations, provides fundamental physical insights that complement empirical observations. Domain expertise captured in structured databases helps contextualize new findings within the broader landscape of materials science. This synthesis of theoretical understanding, experimental data, and domain knowledge creates a robust framework for materials discovery and optimization.</p> <h3>Future Directions</h3> <p><strong>Inverse design. </strong>The future of AI-driven materials synthesis holds exciting possibilities for advancing the field. Inverse design approaches are becoming more sophisticated, enabling researchers to work backward from desired properties to determine viable synthesis routes. This capability dramatically accelerates the development of materials with specific target characteristics.</p> <p><strong>Multi-modal learning. </strong>This learning paradigm represents another frontier, as researchers develop systems capable of integrating diverse data types including spectroscopic measurements, crystallographic information, and microscopy images. This comprehensive approach provides deeper insights into synthesis mechanisms and material properties.</p> <p><strong>Interpretability. </strong>The development of interpretable AI models promises to bridge the gap between predictive power and mechanistic understanding. Rather than treating AI systems as black boxes, researchers are creating models that can provide insights into the fundamental principles governing successful synthesis strategies.</p> <p><strong>Specific-area materials design. </strong>Sustainable materials design has emerged as a critical focus area, with AI tools being leveraged to optimize synthesis conditions for minimal environmental impact while maintaining or improving material performance. This approach aligns with broader societal goals of developing more sustainable technologies and manufacturing processes.</p> <p>The fundamental intersection of AI and materials synthesis, emphasizes both the technological depth and practical constraints that shape the field. The integration of AI tools, particularly deep learning and language models, with traditional materials science approaches continues to accelerate the discovery and optimization of new materials.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0b278f487a86" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://pub.aimind.so/ai-for-material-synthesis-science-a-brief-introduction-0b278f487a86">AI for Material Synthesis Science: A Brief Introduction</a> was originally published in <a href="https://pub.aimind.so">AI Mind</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Can Language Models “Understand” the World? A Misleading Question</title><link href="https://dandelionym.github.io/blog/2024/can-language-models-understand-the-world-a-misleading-question/" rel="alternate" type="text/html" title="Can Language Models “Understand” the World? A Misleading Question"/><published>2024-08-22T05:24:04+00:00</published><updated>2024-08-22T05:24:04+00:00</updated><id>https://dandelionym.github.io/blog/2024/can-language-models-understand-the-world-a-misleading-question</id><content type="html" xml:base="https://dandelionym.github.io/blog/2024/can-language-models-understand-the-world-a-misleading-question/"><![CDATA[<p>The concept of “<strong>understanding</strong>” is inherently subjective, especially when evaluating GPT-series models, which are often considered black boxes. Different people may hold varying perspectives on what constitutes understanding. <strong>While some argue that GPT-4 lacks true comprehension, it’s worth questioning how we measure understanding in humans.</strong> What level of performance or test scores can definitively distinguish between a solid grasp of concepts and mere conjecture?</p> <p>I contend that framing the debate around whether these models “understand” is misleading.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*GZ-CbE5OqMdWw9Pt"/><figcaption>Photo by <a href="https://unsplash.com/@benwhitephotography?utm_source=medium&amp;utm_medium=referral">Ben White</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure> <p>Let’s start by discussing the <strong>reasoning process</strong>. The most effective approach is to view it from the perspective of general learning. This process is analogous to how humans acquire knowledge through reading, frequent reflection, memorization, and interaction.</p> <p>The reasoning ability of language models can be understood as a reflection of rationality in cognition, or as a data-centric learning problem, rooted in continuous learning from large-scale datasets. Within these human-annotated datasets, cognitive logic and causality from a human perspective are evident. The design of these models aims to enable them to learn both implicit and explicit correlations from token-level representations (commonly understood as word-level, though it’s more nuanced than just individual words). The process of learning natural language tokens is akin to learning images at the pixel level. For instance, just as one can generate images by understanding the distribution of pixels (e.g., mouths are located at the bottom of faces, symmetrical eyes, etc.), in language processing, a “pixel” corresponds to a token. The distribution of a sentence (comprising multiple tokens) conveys information in a way that mirrors human recognition of patterns and characteristics.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*YQgo0ViHx9cpgJ2v.png"/><figcaption>Features or representations provided by a good DNN model should encode meaning related to the current task (in this case, classification). With this representation, similar data items are <em>closer</em> to each other (right side); the original non-linear problem is now linearly separable, and therefore easier to solve. (referenced from <a href="https://blog.fastforwardlabs.com/2020/11/15/representation-learning-101-for-software-engineers.html">Deep Representation Learning: What and Why!</a> )</figcaption></figure> <p>Thus, the central issue is <strong>representation</strong> — specifically, how much valuable information has been learned from the inherently noisy and sparse datasets. How can we efficiently extract and represent knowledge during the learning process?</p> <p><strong>Professionally but directly, </strong>the illustration of learning and representation leads to the question of <strong>how effectively the learning process can optimize probability, regarding whether language models can understand</strong>. This is why the reasoning ability of a language model is theoretically limited by the original rationality present in the dataset. <strong>It is important to remember that a language model is not a human-like being.</strong> People often mistakenly treat these advanced models as if they possess human qualities. However, they are more accurately described as <strong>complex functions</strong> designed to compress information by maximizing the representation of the balance between every detail and microstructure in the data, regardless of the extent of human knowledge embedded within it.</p> <p>Instead of asking whether these language models can understand things, <strong>we may need to focus more on how effectively they perform specific tasks in a learning-and-inference fashion.</strong> Humans do not design the world, and machine logic is not entirely a human creation.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8cb1e9e0615e" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Are Physicochemical Mechanisms Important to Agent for Science?</title><link href="https://dandelionym.github.io/blog/2024/are-physicochemical-mechanisms-important-to-agent-for-science/" rel="alternate" type="text/html" title="Are Physicochemical Mechanisms Important to Agent for Science?"/><published>2024-07-18T07:10:04+00:00</published><updated>2024-07-18T07:10:04+00:00</updated><id>https://dandelionym.github.io/blog/2024/are-physicochemical-mechanisms-important-to-agent-for-science</id><content type="html" xml:base="https://dandelionym.github.io/blog/2024/are-physicochemical-mechanisms-important-to-agent-for-science/"><![CDATA[<p>People are increasingly turning to the powerful capabilities of current large language models (LLMs) for AI applications in science, driven by their improving accuracy and methodologies. But what exactly is the intelligence?</p> <p>Even without formal theoretical analysis, <strong>I believe true intelligence would be characterized by performing tasks like humans — continuous self-learning and improvement in any environment. </strong>It is similar to human beings, trained on general tasks that already contain fundamental reasoning and memory. It can also perform well in specific tasks in professional disciplines with a little adaption. That’s why the undeniable fact is that for a long time, computer scientists have prioritised general tasks over the diverse abilities that expect an agent to outperform in specific or professional scenarios as well.</p> <p>AI for Science is not a novel area yet more challenging in perspective. Compared to those 99% abilities to support an AI model well-act in general scenarios, that 1%, importantly, for some reason may lead to suffering results in the end, and it’s often the 1% of tasks that lead to significant challenges. These times, people are saying they will solve protein folding or materials designing problems, as they believe the frontiers for sure with 1% are in front of the eye. Notably, there is also an obvious way to let AI behave like humans with specific abilities that are always across disciplines — anybody can tune the model and then directly run queries with prompts upon LLMs, or at a higher level we design some algorithms to let it avoid errors. It is promising that we are all in LLMs for pursuing an AGI.</p> <p>The crux of the issue lies in <strong>understanding how these models can mimic the human ability to comprehend and interact with the physical world</strong>. At the point of comprehension, it is physicochemical mechanisms that define the world, while at the interaction level, rationality shows us perfect cognition.</p> <p>However, it remains a blank area for people to understand the world from a pure physicochemical mechanisms level, instead, they stand on the statistical results and act as a king of Arther. You probably agree that LLMs excel at processing and generating language, but they lack the inherent understanding of the physical world that humans possess. This gap is significant when it comes to scientific applications, where the interplay of physical laws and chemical processes is crucial. For instance, predicting molecular interactions or understanding the behaviour of complex systems requires more than just linguistic proficiency; it demands a deep integration of scientific knowledge and reasoning.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*bucdFyhg_waQDSgZ"/><figcaption>Photo by <a href="https://unsplash.com/@cdc?utm_source=medium&amp;utm_medium=referral">CDC</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure> <p>To bridge this gap, <strong>it’s essential to develop models that can not only process language but also simulate and reason about physicochemical phenomena.</strong> This requires a multidisciplinary approach, combining advances in AI with insights from physics, chemistry, and biology. By embedding these principles into the training and architecture of LLMs, we can enhance their ability to perform scientific tasks more effectively.</p> <p>Moreover, the integration of sensorimotor capabilities with LLMs can lead to more holistic AI systems. By enabling agents to interact with their environment and gather empirical data, we can foster a more profound understanding of physical processes. This approach mirrors the way humans learn and adapt, through continuous interaction and feedback from the world around them. But anyway, it is the well-defined physicochemical principles that promote the basic understanding of the world, something like causal, or facts with rule-like structures.</p> <p>Stand on the frontier of current AI, I believe we may need more progress towards the essence of AI for Science — that is, leveraging those fundamental principles in the real world to make AI powerful, and assessing their abilities of comprehension in professional knowledge.</p> <p>To go back to the title, I think we even don’t know what the physicochemical mechanisms, simple principles, or great laws are, in the context of AI for Science. But one more unassured guess, if there is one more try to leverage these most advanced technologies, one may realize that the true mechanisms of the world are not all in the sampled data — what machines learned from existing data is only the differences among perspectives of interpreting it with randomness.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=98f9812bc04d" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://pub.aimind.so/are-physicochemical-mechanisms-important-to-agent-for-science-98f9812bc04d">Are Physicochemical Mechanisms Important to Agent for Science?</a> was originally published in <a href="https://pub.aimind.so">AI Mind</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry></feed>